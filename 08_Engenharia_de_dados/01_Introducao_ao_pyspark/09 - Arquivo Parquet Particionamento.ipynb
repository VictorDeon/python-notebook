{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace3edb6-b40e-4400-9894-063e24a79733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Documentação parquet particionado\n",
    "\n",
    "https://spark.apache.org/docs/latest/sql-data-sources-parquet.html \n",
    "\n",
    "O formato Parquet é amplamente utilizado para armazenamento de dados em ambientes distribuídos devido à sua eficiência de compressão e leitura. Uma das principais vantagens do Parquet é o suporte nativo à partição de dados, permitindo organizar grandes volumes de informações em diretórios particionados por colunas, como datas ou categorias. Isso facilita consultas mais rápidas e eficientes, pois apenas as partições relevantes são lidas durante a análise. Nesta seção, exploraremos como criar, ler e manipular arquivos Parquet particionados utilizando o Apache Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b024923-3f99-4fb3-a1ea-b50798664968",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path = \"/Volumes/workspace/default/tutorial/assets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56c1f59-a3fc-4988-a93f-b3fd96466067",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfpq = spark.read.parquet(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET\")\n",
    "display(dfpq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab14d444-00ae-4c31-9c42-84f8f87f5710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificando dados distintos de colunas com spark sql\n",
    "display(dfpq.select(\"Classificacao_da_Ocorrência\").distinct())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "068101e3-ca8a-407a-9ce8-52330f0c0494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfpq.write \\\n",
    "    .partitionBy(\"Classificacao_da_Ocorrência\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_PARTICIONED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f62862c6-24ae-491b-a601-0f7fcff2e159",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3977877c-b7d9-4515-8823-a329ba75a5df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Vendo Arquivos particionados\n",
    "\n",
    "O Apache Spark permite trabalhar com arquivos Parquet particionados, que são organizados em subdiretórios conforme valores de uma ou mais colunas. Isso facilita a consulta eficiente de grandes volumes de dados, pois apenas as partições relevantes são lidas durante a análise. Nesta seção, veremos como visualizar e explorar a estrutura desses arquivos particionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86a85fd3-a419-4089-919f-1f9529933d1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_PARTICIONED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79d5398b-aa9c-4566-b6e6-19f3fd5555de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Descendo mais um nivel ver os logs de cada partição\n",
    "display(dbutils.fs.ls(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_PARTICIONED/Classificacao_da_Ocorrência=Acidente/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05caff1d-0097-4c69-a52d-7bf7c7646928",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfacidente = spark.read.parquet(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_PARTICIONED/Classificacao_da_Ocorrência=Ocorrência de Solo/\")\n",
    "display(dfacidente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b22996e-c925-46e9-9273-dc10506a591b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ler todos os dados mesmo particionados (agrupados)\n",
    "\n",
    "Ao trabalhar com arquivos Parquet particionados, é comum que os dados estejam organizados em subdiretórios conforme valores de uma ou mais colunas. No entanto, em algumas situações, pode ser necessário ler todos os dados disponíveis, independentemente das partições existentes. Nesta seção, veremos como o Apache Spark permite acessar e processar o conjunto completo de dados, mesmo quando eles estão distribuídos em múltiplas partições, garantindo flexibilidade e eficiência na análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b39363-71ab-4390-86c0-c6d572be3e29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfTudo = spark.read\\\n",
    "    .format(\"parquet\")\\\n",
    "    .load(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_PARTICIONED\")\n",
    "\n",
    "display(dfTudo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50f91601-43c9-4309-a476-eb80292b7cbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Salvando em mais de 1 partição\n",
    "\n",
    "Ao salvar dados em formato Parquet utilizando o Apache Spark, é possível particioná-los em múltiplas colunas, como data e categoria, criando uma estrutura de diretórios aninhados. Essa abordagem permite organizar grandes volumes de dados de forma eficiente, otimizando consultas e facilitando a manutenção. Nesta seção, veremos como salvar um DataFrame em mais de uma partição, aproveitando os benefícios do particionamento múltiplo para análises mais rápidas e flexíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c875af1-c5f8-4d3b-9234-321052d4e7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Uma equipe de cada estado analisa as \"Classificacao da Ocorrência\" e cada uma das ocorrencias é analizado por uma pessoa.\n",
    "# Separarar (particionar por Classificacao da Ocorrência e estado)\n",
    "\n",
    "dfpq.write \\\n",
    "    .partitionBy(\"UF\", \"Classificacao_da_Ocorrência\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .parquet(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_MULTIPARTICIONED\")\n",
    "\n",
    "#Obs: pode demorar na escrita devido aos particionamentos , mas ganha tempo na leitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "110c316d-1bc0-409f-abda-04dcb647b774",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c68235f1-1a39-4bb7-96be-cbae9e60e612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_MULTIPARTICIONED\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8814ffe-c260-4989-990e-20504ffbfae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_MULTIPARTICIONED/UF=MG/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c94b5a3-dfb4-4357-b9cf-06bc5ea645d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_MULTIPARTICIONED/UF=MG/Classificacao_da_Ocorrência=Acidente/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65db3fc0-b4e0-44ef-9996-744319a45dd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simulando o responsavel de Mg onde a Classificacao da Ocorrência seja igual a Acidente.\n",
    "dfmg = spark.read \\\n",
    "    .format(\"parquet\") \\\n",
    "    .load(f\"{path}/V_OCORRENCIA_AMPLA_PARQUET_MULTIPARTICIONED/UF=MG/Classificacao_da_Ocorrência=Acidente/\")\n",
    "\n",
    "display(dfmg)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2740228763695004,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "09 - Arquivo Parquet Particionamento",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
