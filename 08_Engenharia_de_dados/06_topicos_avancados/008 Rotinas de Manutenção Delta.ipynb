{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da0f6dfe-dc9e-4dec-aa59-8c8c9f05fe72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Resumo das Rotinas de Manutenção:\n",
    "- **Vacuum**: Remove arquivos antigos para liberar espaço.\n",
    "- **Optimize**: Combina arquivos pequenos para melhorar a performance de leitura.\n",
    "- **Z-Ordering**: Organiza os dados para melhorar o desempenho em consultas filtradas.\n",
    "- **Update/Delete**: Permite operações eficientes de modificação de dados.\n",
    "- **History/Time Travel**: Audita e acessa versões anteriores dos dados.\n",
    "- **Compaction**: Agrupa arquivos pequenos para melhorar a eficiência de leitura.\n",
    "- Essas práticas de manutenção são fundamentais para gerenciar com eficiência um Delta Lake, mantendo a performance e a integridade dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce51ca10-cbb6-459c-aeb7-fa82b1276af1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Manter um** Delta Lake** bem gerenciado é fundamental para garantir a performance, a integridade dos dados e o uso eficiente de recursos. Aqui estão as principais rotinas de manutenção do Delta Lake, quando, como e por que usá-las:\n",
    "\n",
    "### 1. Vacuum\n",
    "**Quando usar**: Para remover arquivos antigos que não são mais necessários, como aqueles gerados por operações de update, merge ou delete.\n",
    "\n",
    "**Por que usar**: O Delta Lake mantém versões antigas de dados (histórico) para fornecer recursos como time travel e rollback. Com o tempo, esses arquivos antigos podem consumir muito espaço em disco. O vacuum remove esses arquivos, liberando espaço.\n",
    "\n",
    "**Recomendação**: Evite configurar o período de retenção abaixo de 7 dias sem considerar as implicações no time travel. O padrão de 7 dias é seguro para manter a possibilidade de recuperação de dados e, ao mesmo tempo, limpar arquivos obsoletos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abf5c94e-5c83-4c84-bcc6-6d78a6bf2581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Define os caminhos de armazenamento no Data Lake\n",
    "gold_path = \"/Volumes/workspace/store/gold/vendas/fato_vendas\"\n",
    "\n",
    "# Disable retention duration check\n",
    "spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\n",
    "# Executa vacuum para remover arquivos não utilizados com mais de 7 dias\n",
    "delta_table = DeltaTable.forPath(spark, gold_path)\n",
    "delta_table.vacuum(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e72ef92-402b-44e9-af99-a2f152f246d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Optimize\n",
    "**Quando usar**: Para otimizar o layout dos arquivos armazenados no Delta Lake, especialmente após muitas operações de escrita ou atualização que podem gerar arquivos pequenos.\n",
    "\n",
    "**Por que usar**: O Delta Lake pode acabar com muitos arquivos pequenos após operações de escrita ou merge. Isso pode prejudicar o desempenho das consultas devido ao overhead de leitura de muitos arquivos. O optimize combina arquivos pequenos em arquivos maiores, melhorando a leitura e o processamento.\n",
    "\n",
    "**Recomendação**: Use o optimize em intervalos regulares ou após grandes operações de escrita, para garantir que o layout dos dados continue eficiente. Para melhorar ainda mais o desempenho, o optimize pode ser combinado com Z-Ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ca09092-9d19-498a-bc46-6714a5fccac0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "# Define os caminhos de armazenamento no Data Lake\n",
    "gold_path = \"/Volumes/workspace/store/gold/vendas/fato_vendas\"\n",
    "# Otimiza a tabela combinando arquivos pequenos em arquivos maiores\n",
    "delta_table = DeltaTable.forPath(spark, gold_path)\n",
    "delta_table.optimize().executeCompaction()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60998b5d-532b-4cec-a82a-a12cb1c59564",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Z-Ordering\n",
    "**Quando usar:** Para otimizar as consultas que realizam filtragens frequentes em determinadas colunas, como colunas de data ou chave.\n",
    "\n",
    "**Por que usar:** O Z-Ordering melhora o desempenho da leitura ao organizar fisicamente os dados em disco com base em uma coluna ou conjunto de colunas, reduzindo o tempo necessário para buscar os registros filtrados.\n",
    "\n",
    "**Recomendação:** Use o Z-Ordering em colunas que são frequentemente usadas em cláusulas de filtro para melhorar a leitura de dados relacionados. Combine isso com o optimize para ter dados organizados de forma mais eficiente no disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1445b2ca-1544-4a88-a270-b64de321398a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from delta.tables import DeltaTable, DeltaOptimizeBuilder\n",
    "# Executa optimize com Z-Ordering na coluna \"DataVenda\"\n",
    "\n",
    "# Load the Delta table\n",
    "delta_table = DeltaTable.forPath(spark, gold_path)\n",
    "\n",
    "# Execute Z-Ordering optimization on the column \"DataVenda\"\n",
    "#delta_table.optimize().#executeZOrderBy(\"DataVenda\").#execute()\n",
    "\n",
    "spark.sql(f\"\"\"OPTIMIZE delta.`{gold_path}` ZORDER BY (DataVenda)\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ea45982-531c-4ba4-b9db-93ec570754bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Update and Delete Operations (UPSERT)\n",
    "**Quando usar:** Para modificar ou remover dados diretamente em uma tabela Delta, sem precisar sobrescrever a tabela inteira.\n",
    "\n",
    "**Por que usar:** O Delta Lake permite que você faça operações upsert (combinação de update e insert) e delete, o que é fundamental em pipelines de dados que exigem dados corrigidos, removidos ou atualizados continuamente, como tabelas de fatos ou históricos.\n",
    "\n",
    "**Recomendação**: Essas operações são úteis para ajustar os dados de maneira eficiente, especialmente quando o volume de dados não é massivo ou quando os dados precisam ser corrigidos frequentemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa45bd4a-c743-4041-b847-d1921bb2921b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import lit, max, current_timestamp\n",
    "\n",
    "# Carregar a tabela Delta\n",
    "delta_table = DeltaTable.forPath(spark, \"/Volumes/workspace/store/gold/vendas/dim_fabricante\")\n",
    "\n",
    "# Calcular o próximo valor de SK_Fabricante\n",
    "next_sk = delta_table.toDF().select(max(\"sk_fabricante\")).collect()[0][0] + 1\n",
    "\n",
    "# Criar uma nova linha para ser inserida\n",
    "new_row = spark.createDataFrame([\n",
    "    (8, \"Novo Fabricante\", next_sk)  # Supondo que 8 seja um IDFabricante de exemplo\n",
    "], [\"IDFabricante\", \"Fabricante\", \"sk_fabricante\"])\n",
    "\n",
    "# Adicionar a coluna DataAtualizacao com o tipo correto\n",
    "new_row = new_row.withColumn(\"data_atualizacao\", current_timestamp())\n",
    "\n",
    "# Executar a operação de inserção\n",
    "delta_table.alias(\"target\").merge(\n",
    "    new_row.alias(\"source\"),\n",
    "    \"target.IDFabricante = source.IDFabricante\"\n",
    ").whenNotMatchedInsertAll().execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b603f463-4ad2-4da7-b2be-4e7cca220fff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Exemplo de Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72924c9d-07fe-4e15-89fc-250642c5fc19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "# Exemplo de update\n",
    "delta_table = DeltaTable.forPath(spark, \"/Volumes/workspace/store/gold/vendas/dim_fabricante\")\n",
    "delta_table.update(\n",
    "    condition = col(\"IDFabricante\") == 7,  # Condição de update\n",
    "    set = { \n",
    "        \"Fabricante\": \"'VanArsdel Inc.'\",\n",
    "        \"data_atualizacao\": current_timestamp()\n",
    "    }  # Atualização de valor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "431d48be-dc38-4a3a-9768-d557edc1e8d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Exemplo de Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61be8716-c6bb-45fb-89f9-782b2beb7840",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exemplo de delete\n",
    "delta_table.delete(condition = col(\"IDFabricante\") == 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "033bddbf-ee9f-4d7e-aff8-49e44a51d187",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Exemplo de UPSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47cc1f66-58e0-492d-acb7-16cc338965d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import monotonically_increasing_id, current_timestamp\n",
    "\n",
    "# Carregue o DataFrame de origem (novos dados)\n",
    "df_silver = spark.read.format(\"parquet\").load(\"/Volumes/workspace/store/gold/vendas\")\n",
    "\n",
    "#Nome tabela destino\n",
    "tb_destino = \"dim_fabricante\"\n",
    "\n",
    "# Extrair produtos únicos para a dimensão Fabricante    \n",
    "dim_fabricante_df = df_silver.select(\"IDFabricante\", \"Fabricante\").dropDuplicates()\n",
    "\n",
    "# Adicionar chave substituta (surrogate keys)\n",
    "dim_fabricante_df = dim_fabricante_df \\\n",
    "    .withColumn(\"sk_fabricante\", monotonically_increasing_id()+1)\n",
    "\n",
    "# Carregue o DataFrame de destino (tabela existente)\n",
    "df_target = DeltaTable.forPath(spark, \"/Volumes/workspace/store/gold/vendas/dim_fabricante\")\n",
    "\n",
    "# Realize a operação de merge\n",
    "df_target.alias(\"target\").merge(\n",
    "    dim_fabricante_df.alias(\"source\"),\n",
    "    \"target.IDFabricante = source.IDFabricante\"\n",
    ").whenMatchedUpdate(set={\n",
    "    \"Fabricante\": \"source.Fabricante\",\n",
    "    \"SK_Fabricante\": \"source.SK_Fabricante\",\n",
    "    \"data_atualizacao\": current_timestamp()\n",
    "}).whenNotMatchedInsert(values={\n",
    "    \"Fabricante\": \"source.Fabricante\",\n",
    "    \"IDFabricante\": \"source.IDFabricante\",\n",
    "    \"SK_Fabricante\": \"source.SK_Fabricante\",\n",
    "    \"data_atualizacao\": current_timestamp()\n",
    "}).execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "144a9fe4-41d5-4a9d-8bd7-c77b68f9407d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 5. History e Time Travel\n",
    "**Quando usar:** Para auditar mudanças na tabela Delta ou para acessar versões anteriores dos dados.\n",
    "\n",
    "**Por que usar:** O Delta Lake mantém um log de transações que permite rastrear todas as modificações feitas na tabela. Isso é útil para auditoria e recuperação de dados em um ponto anterior no tempo.\n",
    "\n",
    "**Recomendação:** Use o histórico e o time travel para depurar problemas ou restaurar versões anteriores dos dados quando necessário. No entanto, lembre-se de usar o vacuum para gerenciar a quantidade de histórico mantido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "254a5b63-4140-416b-ad34-1c67b01efc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Acessando o histórico da tabela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59ae9ecd-4a94-45f4-916a-aad8dd0845a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Visualizar o histórico da tabela Delta\n",
    "history_df = DeltaTable.forPath(spark, \"/Volumes/workspace/store/gold/vendas/dim_fabricante\").history()\n",
    "\n",
    "display(history_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9432069-a818-4938-9a60-5391f522c001",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Acessar versões antigas (Time Travel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa738c28-98f2-44f9-968d-924c9ebf9f7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Acessar a versão 5 da tabela\n",
    "df = spark.read.format(\"delta\").option(\"versionAsOf\", 2).load(\"/Volumes/workspace/store/gold/vendas/dim_fabricante\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf762956-9d1e-4427-80f8-80ad52e92a15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 6. Restaurar uma versão antiga de tabela Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e662a897-9466-4bc6-9482-cd9fdabde9a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Inicializar DeltaTable\n",
    "delta_table_path = \"/Volumes/workspace/store/gold/vendas/dim_fabricante\"\n",
    "delta_table = DeltaTable.forPath(spark, delta_table_path)\n",
    "\n",
    "# Restaurar a tabela para a versão \n",
    "delta_table.restoreToVersion(0)\n",
    "\n",
    "# Apresentar a tabela\n",
    "display(spark.read.format(\"delta\").load(delta_table_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6d68c04-5cc9-476d-bbb5-e9446ab74129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**7. Compaction (Compactação)**\n",
    "\n",
    "**Quando usar**: Para agrupar arquivos pequenos resultantes de múltiplas operações de escrita em arquivos maiores, melhorando a performance de leitura.\n",
    "\n",
    "**Por que usar**: Com o tempo, as operações de escrita podem gerar muitos arquivos pequenos, resultando em um número excessivo de partições pequenas, o que afeta a performance. A compactação agrupa esses arquivos pequenos para melhorar o desempenho de leitura e reduzir o overhead.\n",
    "\n",
    "**Recomendação:** Execute operações de compactação regularmente ou após grandes operações de escrita para manter o layout dos dados em arquivos otimizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a12ace-86d2-4d3b-ade5-0cc32eea702b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reparticionando a tabela fato_vendas por ano e mês e salvando o resultado\n",
    "# Agrupando os arquivos pequenos em arquivos maiores\n",
    "df = spark.read.format(\"delta\").load(\"/Volumes/workspace/store/gold/vendas/fato_vendas\")\n",
    "df.repartition(2).write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/store/gold/vendas/fato_vendas_repart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ebc3983-ca8c-49b4-92cb-157c003d6dc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "**1. Particionamento com `repartition`**\n",
    "\n",
    "O `repartition` é utilizado para aumentar ou reduzir o número de partições de forma uniforme, redistribuindo os dados através de um shuffle. Útil quando você precisa de mais paralelismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88a8cb60-f71f-479c-95db-bec31dcb5ad4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Exemplo de criação de um DataFrame \n",
    "df_geo = spark.read.format(\"delta\").load(\"/Volumes/workspace/store/gold/vendas/dim_geografia\")  \n",
    "# Lendo um arquivo Parquet como exemplo\n",
    "\n",
    "# Verificar número de partições iniciais\n",
    "print(f\"Número de partições iniciais: {df_geo.rdd.getNumPartitions()}\")\n",
    "\n",
    "# Redefinir para 2 partições usando repartition\n",
    "df_reparticionado = df_geo.repartition(2)\n",
    "\n",
    "# Persiste os dados em uma tabela Delta\n",
    "df_reparticionado.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").save(\"/Volumes/workspace/store/gold/vendas/geo_repart\")\n",
    "\n",
    "# Verificar número de partições após repartition\n",
    "print(f\"Número de partições após repartition: {df_reparticionado.rdd.getNumPartitions()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f26bb12-7208-42a4-ac54-a7d470c5325e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "**2. Reparticionamento com Coluna Específica**\n",
    "\n",
    "Se o dataset contiver uma coluna-chave (como Regiao ou Data), você pode usar o repartition para redistribuir os dados com base em uma coluna específica, o que pode ser útil para garantir que os dados relacionados sejam processados juntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48b560b3-8201-4158-a0bf-7214ab45a467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_geo = spark.read.format(\"delta\").load(\"/Volumes/workspace/store/gold/vendas/dim_geografia\")  \n",
    "# Reparticionando os dados pela coluna \"Regiao\"\n",
    "df_reparticionado_geo = df_geo.repartition(10, \"Regiao\")\n",
    "\n",
    "\n",
    "# Persiste os dados em uma tabela Delta\n",
    "df_reparticionado_geo.write.partitionBy(\"Regiao\").format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").save(\"/Volumes/workspace/store/gold/vendas/geo_regiao\")\n",
    "\n",
    "# Verificar número de partições após reparticionar pela coluna \"Regiao\"\n",
    "print(f\"Número de partições após reparticionar pela coluna Regiao: {df_reparticionado_geo.rdd.getNumPartitions()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4bcdddc-25e2-4a96-b358-850653964449",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%md\n",
    "**3. Redução de Partições com `coalesce`**\n",
    "O `coalesce` é utilizado para reduzir o número de partições sem realizar um shuffle, o que é útil quando se deseja consolidar partições e reduzir o número de tarefas, como ao escrever para o disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb6a204b-2a31-41d3-91b7-acd4973034de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Usando coalesce para reduzir as partições para 5\n",
    "df_coalesced = df_geo.repartition(100).coalesce(5)\n",
    "\n",
    "# Persiste os dados em uma tabela Delta\n",
    "df_coalesced.write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/store/gold/vendas/geo_coaslece\")\n",
    "\n",
    "# Persiste os dados em uma tabela Delta\n",
    "df_coalesced.write.format(\"delta\").option(\"overwriteSchema\", \"true\").mode(\"overwrite\").save(\"/Volumes/workspace/store/gold/vendas/geo_coalesce\")\n",
    "\n",
    "# Verificar número de partições após o coalesce\n",
    "print(f\"Número de partições após coalesce: {df_coalesced.rdd.getNumPartitions()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23fbe91b-a5dc-41ca-979e-86168956cfe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Resumo das Técnicas:**\n",
    "\n",
    "- `repartition(n)`: Redistribui os dados uniformemente em n partições. Útil para aumentar o número de partições ou garantir uma melhor distribuição.\n",
    "- `repartition(col)`: Redistribui os dados com base em uma ou mais colunas, garantindo que valores semelhantes estejam na mesma partição.\n",
    "- `coalesce(n)`: Reduz o número de partições sem um shuffle, consolidando as partições existentes de forma eficiente.\n",
    "\n",
    "**Quando Usar:**\n",
    "\n",
    "- `repartitio`n: Use quando quiser aumentar o número de partições ou redistribuir os dados de forma mais equilibrada, especialmente quando houver um número elevado de partições pequenas.\n",
    "- `coalesce`: Use quando estiver reduzindo o número de partições para minimizar o shuffle e consolidar os dados, especialmente ao escrever dados para armazenamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6dfe733c-f54b-4872-9a16-612cbfa2b585",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Evidências de repartição/Compactação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ac56f94-0395-4769-8cf5-68ff4c238ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/store/gold/vendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc41ff1d-cfca-40d7-b97a-919e8f507239",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/store/gold/vendas/fato_vendas_repart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bc85037-c1ff-4ff1-a7d6-c5d822fbfddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/store/gold/vendas/geo_repart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fd64cad-c92e-4410-8155-5d6a16188143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/store/gold/vendas/geo_regiao/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e5caa97-6c8a-4517-9f25-dd6f1c256bc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls /Volumes/workspace/store/gold/vendas/geo_coalesce/"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5232872374287559,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "008 Rotinas de Manutenção Delta",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
